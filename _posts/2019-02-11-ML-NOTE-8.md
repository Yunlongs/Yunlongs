---
layout:     post
title:      吴恩达Stanford机器学习公开课（八）笔记
subtitle:   Lecture 8 - Kernels.SMO algorithm.
date:       2019-02-11
author:     Yunlongs
catalog: true
tags:
    - 机器学习
    - 吴恩达Stanford机器学习公开课
---

>网易公开课视频地址：http://open.163.com/movie/2008/1/M/C/M6SGF6VB4_M6SGHFBMC.html?frm=record
课程主页地址：http://cs229.stanford.edu/
课程讲义下载地址：https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/Books/cs229-notes3.pdf


# Lecture 8 - Kernels.SMO algorithm.

## 核(Kernels)
现在让我们回到之前线性回归的讨论之中，我们根据输入`x`（房屋大小）使用特征`x,x^2,x^3`来获得一个三次函数，为了区分这两中类型的变量，我们把**原始输入值称之为问题的属性** （房屋大小x），把**原始输入经过映射后的那些将要在学习算法中使用的量 称之为输入特征** ,同时把原始输入到输入特征之间的映射`φ`称之为**特征映射** 。例如：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-8-1.jpg)

`SVM算法使用的是特征φ(x)，因此我们将在所有地方都使用φ(x)而不再是x`

因为算法可以使用内积`<x,z>`来完全表示，我们可以将所有的内积替换为`<φ(x), φ(z).>`。当有了映射φ后，**定义核（Kernel）** 如下：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-8-2.jpg)
`这意味着我们可以将算法中所有的<x,z>简单的替换为K（x,z）`

**当φ(x)是特别高维度的向量，即使映射本身特别难计算，计算出K(x,z)将不会那么的难。** 基于这种设定，即使没有很明确的表示出映射φ(x)，通过很高效的计算出K(x,z)，我们可以使得SVM在非常高维的空间中进行学习。

-----
为了解释这些，举一个例子：

假设x，z都是n为向量，且
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-8-3.jpg)
将上式展开为：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-8-4.jpg)

**如果n=3时，特征映射被给如下，那么我们可以得到K(x,z)=φ(x)Tφ(z)** 

![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-8-5.jpg)
`注意，即使计算高维向量需要O(n^2)的时间复杂度，但是根据输入属性的线性，找到K(x,z)只需要O(n)的时间复杂度.`

对于一个相关的kernel，我们考虑
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-8-6.jpg)
找到n=3时的特征映射如下：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-8-7.jpg)
`其中，参数c的作用是控制xi（一阶）和xixj（二阶）之间的相对权重`

>更宽泛的说，kernel  K(x, z) = (xTz + c)^d等同于到(n+d,d)特征空间的特征映射，所有单项式xi1xi2xi3..的阶最多到d。然而尽管SVM要在O(n^d)的多维空间中运行，在没有给定确切特征向量的情况下，计算K(x, z)仍然将只花费O(n)的时间。

------
现在让我们换一个略微不同的视角看到kernels，直观上来说，如果φ(x)和φ(z)比较接近，那么`K(x,z)=φ(x)Tφ(z)`可能会大；相反的，如果φ(x)和φ(z)距离很远（几乎垂直），那么kernel将会很小。所以，**我们可以把kernel当作φ(x)和φ(z)相似程度的测量手段。**

例如，我们可以选用如下**高斯kernel** 来当作测量x与z相似度的手段，并作为kernel应用到SVM中。
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-8-8.jpg)

下面来检验kernel的合法性，即是否存在φ，使得`K(x,z) = <φ(x),φ(z)>`。
假设有m个点的集合{x1,...,xm}，kernel  K为m-m阶的方阵,Kij=K(xi，xj)。
因此，可以推导出下列式子：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-8-9.jpg)
`现在让我们回顾线代中，正定矩阵的定义，存在z>0,使得zTkz>0，故K是正定矩阵。而这里z是随机变量，故K是半正定矩阵，相反也成立。此条件为充要条件`
**定理（Mercer）:如果K是n阶方阵，对于任意的{x1,...,xm}，K是一个有效的kernel的充要条件是，K是半正定矩阵。**
通过Mercer定理，可以让我们**不必在找到一个符合kernel的特征映射φ**，而是对kernel矩阵进行判定即可得知kernel是否有效。

>接下来，让我们简单的讨论些kernels在其他例子中的使用。在**数字验证码识别问题** 中，在SVM中使用简单的*多项式kernel K(x,z)=(xTz)^d* 或者*高斯kernel* 都可以获得非常不错的效果，甚至在没有任何关于视觉和邻接像素先验知识并且输入属性x是256维度图片像素密度向量的情况下，它的表现尤其惊人的好。在**字符串分类问题** 中，很难去构造一个合理的“小”的特征集合，尤其是当字符串长度还未定时；然而，如果令φ(x)成为k长度的字符出现次数，在英文信封中将会得到26^k个这样的字符串，这很难去有效的计算它。但是使用字符串学习算法(dynamic programming-ish)，不给出明确的特征映射φ，高效地计算kernels是可能的。

吴老师最后还给出了一个小技巧，叫**kernel trick** ：如果您的学习算法可以写成只有输入属性向量之间内积的形式<x,z>，就可以将其替换为K(x,z)，然后你就会“奇迹般”的发现你的算法也可以在高纬度空间中高效的运作。


## 线性不可分
在将这部分之前，老师对SVM算法做了一个形象性的描述。如下图：左边是在一维上的一组线性不可能的数据样本，通过高斯kernel将一位样本映射到了高维空间中，然后在高维度空间中使用SVM算法再对数据样本进行分割。
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-8-10.jpg)

虽然说，将数据映射到了高维空间很大程度的加大了其线性可分的可能性，但是仍然不能保证其在高维是可分的。并且还存在一个问题，有时并不能很确定分割超平面就是我们所想要寻找的那样，例如下图：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-8-11.jpg)
`从图中可以看出，当原先样本加了一个较为偏离的样本点后，超平面发生了很大的变化，并且其距样本点的距离离变小了很多。`

为了能够是使算法应用于线性不可分的数据集和降低对外入的点的敏感性，我们把之前的优化目标重新更定如下：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-8-12.jpg)
`这允许我们的函数距离小于1并且当函数距离为1 − ξi时，需要为目标函数增加一些消耗Cξi。参数C控制的是最小化||w||和确保函数距离小于1之间的相关权重。`
 
像之前一样，写出拉格朗日乘法公式如下：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-8-13.jpg)
`其中，α和r是拉格朗日乘数`
将w，b的导数设为0后，将其带入上面的优化问题中，化简可得优化问题的对偶形式：

![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-8-14.jpg)

同时，KKT补充条件（将用于测试SMO算法是否收敛）也要修改为如下：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-8-15.jpg)

>故，在做完这一切后，剩下所需的就是一个能解决对偶问题的算法，将在后续讲解。