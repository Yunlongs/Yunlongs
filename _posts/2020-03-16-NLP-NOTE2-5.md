---
layout:     post
title:      NLP系列近五年突破技术（五）笔记
subtitle:   Lecture 5 - 从BERT到XLNet
date:       2020-03-16
author:     Yunlongs
catalog: true
tags:
    - 机器学习
    - 深度学习
    - “ 共同战疫” NLP系列专题 直播 
---

>课程信息：感谢@李文哲老师，贪心科技--“ 共同战疫” NLP系列专题 直播课，本文所有版权归贪心科技https://www.greedyai.com/所有。

# Lecture 5 - 从BERT到XLNet
因为标签样本的稀缺性，所以我们也同样需要将无标签样本利用起来。
下图为NLP中的一些无监督学习方法：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/NLP/GreedyAI-5/1.png)

## Denoising Autoencoder
这里需要先介绍下Autoencder 与Denising Autencder的区别。

**AutoEncoder**： 如下图，我们希望神经网络能够学习到输入（图片、向量）的紧凑表示(compat represention)，并且能够通过紧凑表示恢复出尽可能与原来相似的图片或者向量。
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/NLP/GreedyAI-5/2.png)

**Denoising AutoEncoder:**  结构和Autoencoder一样，但是我们在输入加了点噪声$x_i + \delta$，并且仍然希望其学习到紧凑表示，并且学习到的紧凑表示仍然能够尽可能的还原出输出$x_i$。

这样能够**使得学习出的紧凑表示更加的鲁邦**
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/NLP/GreedyAI-5/3.png)