---
layout:     post
title:      吴恩达Stanford机器学习公开课（九）笔记
subtitle:   Lecture 9 - Learning Theory.
date:       2019-05-06
author:     Yunlongs
catalog: true
tags:
    - 机器学习
    - 吴恩达Stanford机器学习公开课
---

>网易公开课视频地址：http://open.163.com/movie/2008/1/M/C/M6SGF6VB4_M6SGHFBMC.html?frm=record
课程主页地址：http://cs229.stanford.edu/
课程讲义下载地址：https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/Books/cs229-notes4.pdf

# Lecture 9 - Learning Theory

## 1.偏差/方差 平衡（Bias/variance tradeoff）
当我们之前讨论线性回归时，我们曾经讨论过**简单模型**“$y=\theta_{0}+\theta_{1} x$”和**更复杂模型**“$y=\theta_{0}+\theta_{1} x+\cdots \theta_{5} x^{5}$”的例子，如下：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-9-1.jpg)
在我们使用一阶的模型不足以描绘数据属性时，我们使用五阶建立的模型也不会是很好。即使五阶的模型能够很好的在此训练集中来预测y，但是五阶的模型却不能很好**泛化**地去预测其他的样本。假设的**泛化误差**（将严格地说是正确的）是它不一定在这里训练集中的例子上体现的预期误差。

图中左边和右边的模型都有着很大的泛化误差，但是他们造成泛化误差的类型是不同的。如果熟练集y与x之间的关系不是线性的，那么我们即使对一个大规模训练集拟合一个线性模型，它将不会很精确的捕获数据集中的结构。即使我们将其拟合到很大的数据集中，在这里我们可以**把预期的泛化误差定义为偏差（bias）**。因此对于这个问题来说，我们的模型具有很大的偏差，或者可以说模型**欠拟合**。

在右边的图中，我们成功的根据我们的小的、有限的数据集拟合出了数据的模式，但是用这个5阶的多项式去预测关于更多的y与x的关系将会有很大的风险，这样拟合的模型具有很大的偶然性。通过对这个训练集拟合出这个“不符合数据特征”的模式，我们可以称这个模型具有很大的泛化误差，这本例中我们可以称这个模型具有很大的**方差**。

通常，我们需要在**偏差和方差之间寻找一种平衡**，如果我们的模型过于简单并且有很少的参数，那么它可能有很大的偏差（但是方差很小）；如果我们的模型过于复杂并且有很多的参数，那么它可能有很大的方差（但是偏差很小）。这图中的例子中，对数据拟合一个二次函数相对于其他两个是最好的。

## 2.预备知识
为了能够最好的根据不同的设置来应用不同的算法，我们将会对以下几个问题进行探讨并寻求答案：
1. **我们能否将前面提及的偏差和方差折中给正式化？** 这也将最终引领我们去讨论模型选择方法，例如自动选择几阶的多项式来拟合数据集。
2. 在机器学习中我们真正关系的是泛化误差，但是大多数学习算法都是根据当前的数据集来拟合模型。**为什么在训练集上表现的很好这还能告诉我们有泛化误差呢？更明确些，就是我们可以把训练集上的误差和泛化误差联系在一起吗？**
3. **实际上证明学习算法将会工作的很好这有什么限制条件吗？**

首先介绍两个有用的公理：
1. **（联合概率上界）**：$P\left(A_{1} \cup \cdots \cup A_{k}\right) \leq P\left(A_{1}\right)+\ldots+P\left(A_{k}\right)$
2. **（Hoeffding 不等式）**：$Z_{1}, \dots, Z_{m}$都是服从不二元伯努利分布的独立同分布的随机变量，例如$P\left(Z_{i}=1\right)=\phi$，$P\left(Z_{i}=0\right)=1-\phi$。现在令$\hat{\phi}=(1 / m) \sum_{i=1}^{m} Z_{i}$，并且任何$\gamma>0$都是固定的。可以得到：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-9-5.jpg)

这个定理（在学习原理中也被称为**Chernoff bound**）告诉我们如果采用$\hat{\phi}$来估计$\phi$，即使当m很大时，其和$\phi$的真实值相差很大的概率会很小。

----
我们使用二分类问题$y \in\{0,1\}$来简化我们的探索过程，注意**我们可以将其泛化到其他问题中，包过回归和多分类问题**。 假设给定大小为m的训练集
$S=\{(x^{(i)},y^{(i)});i=1,...,m \}$，训练样本$\left(x^{(i)}, y^{(i)}\right)$是服从概率分布$\mathcal{D}$的独立同分布样本，我们定义假设h的**训练误差**（在学习原理中也被称为**经验风险**或**经验错误**）为：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-9-6.jpg)


我们可以标记$\hatε_S(h)$为对于训练集S的训练误差。我们也可以**定义泛化误差为：**
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-9-7.jpg)
对于线性分类问题，$h_θ(x)=1\{θ^{T} x \geq 0\}$，有什么合理的方式来拟合参数θ呢？一种方法是试图**最小化训练误差**，取
$$\hat{\theta}=\arg \min _{\theta} \hat{\varepsilon}\left(h_{\theta}\right)$$

我们把这个过程叫做**经验风险最小化（ERM）**，并且学习算法得到的假设输出为$\hat{h}=h_{\hat{\theta}}$。我们可以把ERM看待为最基础的学习算法，并且这也是我们将要研究的中心。（类似于逻辑回归之类的算法都可以被视作为ERM的近似算法）

在我们对学习原理的学习过程中，适当的抽象化将是十分有效的。在这里，我们将学习算法所使用的**假设类H**定义为它所考虑的所有分类器的集合。因此，对于线性分类问题，
$$\mathcal{H}=\left\{h_{\theta} : h_{\theta}(x)=1\left\{\theta^{T} x \geq 0\right\}, \theta \in \mathbb{R}^{n+1}\right\}$$是在$\mathcal{X}$（输入域）上所有分类器的集合，其决策界限是线性的。更宽泛的说，如果我们在研究神经网络，那么我们可以让$\mathcal{H}$为一些神经网络结构可以表示的所有分类器。

ERM现在可以被认为是对函数$\mathcal{H}$类的最小化，其中学习算法采用如下假设：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-9-8.jpg)

## 3. 有限H的例子
首先考虑如下学习问题：假设我们有一个有k个假设组成的有限假设类$\mathcal{H}=\{h_{1}, \dots, h_{k}\}$，这样$\mathcal{H}$就成了有k个从$\mathcal{X}$到{0,1}的函数映射集合，并且ERM选择$\hat{h}$为这些k个函数中有最小训练误差的那个。

我们想要对泛化误差$\hat{h}$做出保证，我们可以把策略分为两部分：
1. 我们首先要展示出对于所有的h来说，$\hat{\varepsilon}(h)$是${\varepsilon}(h)$的可靠估计。
2. $\hat{\varepsilon}(h)$的泛化误差有上界。

对任何的$h_{i} \in \mathcal{H}$取值都固定。考虑如下伯努利随机变量$Z$，从$D$中取样$(x, y) \sim \mathcal{D}$，因为我们的训练集是服从$\mathcal{D}, Z$的独立同分布样本，可以定义$Z_j=1\{h_{i}(x^{(j)}) \neq y^{(j)}\}$.

我们**可以看出对随机的一个样本$\varepsilon(h)$错误分类的概率实际上就是$Z_j$的预期值**。更多的，训练误差可以被写为：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-9-8.jpg)

在这里我们可以**应用Hoeffding 不等式**，得到：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-9-10.jpg)

可以看出来，当m很大的时候，对于特别的的$h_i$其训练误差将会很大概率地与繁华误差接近；**但是我们不仅仅想要确保只对一个特指的$h_i$满足$\varepsilon(h)$和$\hat{\varepsilon}(h)$很接近**，我们想要做到的是，正别对于所有的$h \in \mathcal{H}$都同时满足这个规律。为了做到这样，文件哦们现在令事件$A_i$表示$\left|\varepsilon\left(h_{i}\right)-\hat{\varepsilon}\left(h_{i}\right)\right|>\gamma$，根据Hoeffding不等式我们可以得到$P\left(A_{i}\right) \leq 2 \exp \left(-2 \gamma^{2} m\right)$.因此，可以做出如下推导：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-9-2.jpg)
如果我们将上式两边都用1减去，我们发现：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-9-3.jpg)
对于所有样本$h \in \mathcal{H}$的误差都小于$γ$的概率至少为$1-2 k \exp \left(-2 \gamma^{2} m\right)$,这个结果可以被称之为**一致收敛**，这是因为这是对所有的$h \in \mathcal{H}$都同时拥有了一个下界。

-----
在这上面的讨论中，我们所做的事为，给定特定的值m和γ的情况下，对于一些$h \in \mathcal{H},|\varepsilon(h)-\hat{\varepsilon}(h)|>\gamma$的概率给定一个上界或者下界。在这其中有**我们所感兴趣的三个定量：m,γ和错误的概率**；我们可以使用其中的两个来限定另一个量的取值。

举个例子来进行解释，首先回答这个问题：当给定γ和$\delta>0$，我们为了保证训练误差和泛化误差之间的差值小于γ，需要m的值为多少？答案为：通过设$\delta=2 k \exp \left(-2 \gamma^{2} m\right)$并用此来解出m：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-9-11.jpg)

因此就可以徐艳定出我们所需要保证的最少的训练集的数量，为了确保能具有一定等级的效能，算法所需要的训练集的大小m也被称为算法的**取样复杂度**。

其中**最为重要的**的一条属性就是，确保概率的情况下，所需要的训练集的数量仅是关于k的对数形式。

相似地，我们也可以固定m和$\delta$来解出γ在之前的等式中，当概率为$1-\delta$时，对于所有的$h \in \mathcal{H}$我们有：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-9-12.jpg)

当我们选取$\hat{h}=\arg \min _{h \in \mathcal{H}} \hat{ε}(h)$的时候，我们该如何来证明我们的学习算法的泛化是否是正确的呢？
现在定义$h^{\ast}=\arg \min _{h \in \mathcal{H}} ε(h)$为H中最优的假设，所以我们使用$h^{\ast}$来对性能进行比较是很有意义的。如下：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-9-4.jpg)
>第一行是因为样本一致收敛，即$|\varepsilon(\hat{h})-\hat{\varepsilon}(\hat{h})| \leq \gamma$。\
第二行是因为使用$\hat{h}$来最小化$\hat{\varepsilon}(h)$，因此对于所有的h有$\hat{\varepsilon}(\hat{h}) \leq \hat{\varepsilon}(h)$，特别是$\hat{\varepsilon}(\hat{h}) \leq \hat{\varepsilon}\left(h^{\ast}\right)$。\
第三行再次使用了一致收敛，$\hat{\varepsilon}(h^\ast) \leq {\varepsilon}(h^\ast)+\gamma$\
所以我们可以看出来，当均符合一致收敛时，$\hat{h}$的泛化误差最多比$H$中的最优假设糟糕$2γ$。

**定理：** 令$|\mathcal{H}|=k$，所有的m和δ都固定，使概率最少为$1-δ$，我们可以得到：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-9-13.jpg)

这样就可以把我们先前提过的模型选择中的**偏差/方差 折中**给定量化，特别的，当我们给定一个更大的假设类$\mathcal{H}^{\prime} \supseteq \mathcal{H}$是，十字中的第一项 $\min _{h} \varepsilon(h)$只会变小（这是因为其取最小值，只可能比现在更小），这样的话，通过对的一个更大的假设类进行学习，我们的“偏重”只能减少。另外，当k也在增加的同时，式子中第二部分将会增加，并且这也会导致“方差”增加。（注意，这里把第一项看作为偏差，第二项看作为方差，只是近似的，并不是十分的正规）

接着，我们同样也可以得到如下的**取样复杂度界限**：
**Corollary**：令$|\mathcal{H}|=k$，所有$\delta, \gamma$都固定，然后保持$\varepsilon(\hat{h}) \leq \min _{h \in \mathcal{H}} \varepsilon(h)+2 \gamma$的概率最少为$1-δ$，就可以满足：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-9-14.jpg)