---
layout:     post
title:      吴恩达Stanford机器学习公开课（十一）笔记
subtitle:   Lecture 10 - Online learning, Advice for applying Machine Learning
date:       2019-05-19
author:     Yunlongs
catalog: true
tags:
    - 机器学习
    - 吴恩达Stanford机器学习公开课
---

>网易公开课视频地址：http://open.163.com/movie/2008/1/U/O/M6SGF6VB4_M6SGJURUO.html
课程主页地址：http://cs229.stanford.edu/
课程讲义下载地址：https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/Books/cs229-notes6.pdf
和https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/Books/ML-advice.pdf

# Lecture 10 - Online learning, Advice for applying Machine Learning

## Online Learining
在线学习方式是在学习算法在学习的过程中，边学习边预测。

在这样的设定下，假设学习算法被给定一系列的训练样本$\left(x^{(1)}, y^{(1)}\right),\left(x^{(2)}, y^{(2)}\right), \ldots\left(x^{(m)}, y^{(m)}\right)$，**首先给定算法$x^{(1)}$,让算法来估计$y^{(1)}$的值，随后在向算法揭露出真正的$y^{(1)}$值；然后给定$x^{(2)}$，估计$y^{(2)}$，揭露$y^{(2)}$，并依次类推..**

在在线学习过程中，我们最需要注意的是算法整个运行过程中的**总体误差数**,下面我们将使用感知器算法为例子来对在线学习方式的误差做一个约束界限。为了方便导出之后的公式，我们将约定分类标签为$y=\in\{-1,1\}$。

在我们的感知器算法中有参数$\theta \in \mathbb{R}^{n+1}$,它根据公式（1）来做出预测：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-1.jpg)
其中
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-2.jpg)

当给定训练样本$(x, y)$，感知器算法的参数更新规则如下：若$h_{\theta}(x)=y$，则不对参数θ做任何改动；否则，对参数θ做如下更新：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-3.jpg)

下面让我们引出一个定理，这个定理可以对使用在线学习方式的感知器算法每次更新时的误差给定一个界限。**注意西面对误差数的界限约束并没有明显的依赖于样本数m和输入x的维度n。**

**定理（Block,1962,and Novikoff,1962）：** 给定样本$\left(x^{(1)}, y^{(1)}\right),\left(x^{(2)}, y^{(2)}\right), \ldots\left(x^{(m)}, y^{(m)}\right)$，假设对于所有的i都有$\left\|x^{(i)}\right\| \leq D$，并且存在单位向量u满足$y^{(i)} \cdot\left(u^{T} x^{(i)}\right) \geq \gamma$（如果$y^{(i)}=1$，则$u^{T} x^{(i)} \geq \gamma$；如果$y^{(i)}=-1$，则$u^{T} x^{(i)} \leq-\gamma$。这样u就可以把数据分离成边距至少为γ的两半）。这时，感知器算法总共预测出错的个数最多为$(D / \gamma)^{2}$。

----
**定理证明：**感知器算法只会对预测出了问题的样本更新其权值，另$\theta^{(k)}$它做第k次错误预测时使用的权值，所以当$\theta^{(1)}=\overrightarrow{0}$时，如果对该训练集来说存在第k的预测错误，则会有$g\left(\left(x^{(i)}\right)^{T} \theta^{(k)}\right) \neq y^{(i)}$，由此可以推出：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-4.jpg)

同时，从感知器算法的学习规则中，我们也可以得知$\theta^{(k+1)}=\theta^{(k)}+y^{(i)} x^{(i)}$.对其两边同乘单位向量u可以得到：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-5.jpg)
在**根据数学归纳法可以**得到：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-6.jpg)

我们对更新公式两边同时求模，可以得到：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-7.jpg)
第三步使用了等式（2）。再次根据**数学归纳法**可以得到：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-8.jpg)


将（3）和（5）合并可以得到：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-9.jpg)
其中的第二步是因为
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-10.jpg)

所以就可以得出我们的结果$k \leq(D / \gamma)^{2}$。

# Advice for applying Machine Learning

在这一部分，我们主要讨论如下几个论点：
1. 为调试学习算法过程中出现的错误做诊断
2. 误差分析和销蚀分析
3. 如果从一个机器学习问题开始着手

## 对学习算法的调试

**启发式例子：**
反垃圾邮件系统。
1. 你精心挑选了100个单做来当做特征（而不是使用英语词汇表中所有的单词）
2. 用贝叶斯逻辑回归来建模，并使用梯度下降算法。
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-11.jpg)
3. 最后你得到了20%的训练误差，这误差太高了！不可以接受！
4. 然后你该怎么做呢？

**几种常用的调试方法：尝试通过不同的方式来提升算法。**
- 尝试使用更多的训练样本
- 尝试使用更小的特征集合
- 尝试使用更大的特征集合
- 尝试改变特征集合的构成：邮件标题或者邮件主体的特征
- 进行更多次的梯度迭代
- 尝试更换为牛顿方法
- 使用不同的λ值
- 尝试使用SVM建模

这些调试方法可能是能够起作用的，但是全部检查一遍这就太过于耗时了，并且还需要有足够的运气才能最终修复出现的问题。

### 诊断是偏差还是方差的问题
如例子所说，使用贝叶斯逻辑回归的测试误差率为20%。

现在我们就需要来找出是什么原因导致了那么高的误差率。
现在**假设造成这种问题的原因有两种：**
- 过拟合（高方差）
- 太少的特征（高偏差）

现在为了区分到底是高方差还是高偏差造成的问题，我们首先来看下**典型的高方差学习曲线：**
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-12.jpg)
特点如下：
1. 测试误差随着训练集的增大而减小
2. 训练误差和测试误差中间会有很大的空隙

**典型的高偏差学习曲线：**
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-13.jpg)
特点如下：
1. 训练误差会出奇的高
2. 训练误差和测试误差之间仅有很小的空隙

因此，对于此问题我们的**诊断手段**如下：
1. 高方差：训练误差将会比测试误差低非常的多
2. 高偏差：训练误差同样会很高

对于上述方法来说，以下做法可以相应的解决：
- 尝试使用更多的训练样本           （修复高方差问题）
- 尝试使用更小的特征集合           （修复高方差问题）
- 尝试使用更大的特征集合           （修复高偏差问题）
- 尝试改变特征集合的构成：邮件标题或者邮件主体的特征 （修复高偏差问题）

### 其他诊断手段

>偏差以及方差问题是一种常用的诊断手段，但是对于其他的问题们，通常需要利用你自己的聪明才智来构建自己的诊断方法来指出哪里出了问题。

**另一个例子：**
1. 使用贝叶斯逻辑回归，对垃圾邮件判断有2%的误差，对非垃圾邮件的判断同样有2%的误差（这对实际应用来说是过于高的）
2. 使用线性核的SVM算法，对垃圾邮件判断有10%的误差，对非垃圾邮件的判断有0.01%的误差（可以接受的比例）
3. 但是为了计算的高校性，你仍然想要使用逻辑回归。
4. 接着你需要怎么做？

现在让我们来关注机器学习领域中**另一个常见问题**：
你确定你的算法（逻辑回归中的梯度下降）收敛了吗？
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-14.jpg)
`通常很难从目标函数中来看出来算法是否已经收敛`

其他同样常见的问题还有：
- 是否选择了正确的优化函数？例如你目前所关心的为：
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-15.jpg)
- 采用贝叶斯逻辑回归是否适用？λ选择了正确的值？
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-16.jpg)
- 采用SVM是否适用？C选择了正确的值？
![](https://yunlongs-1253041399.cos.ap-chengdu.myqcloud.com/image/Stanford/lecture-11-17.jpg)

尽管SVM的的结果比贝叶斯逻辑回归好，但是你十分想用贝贝叶斯逻辑回归来部署你的应用。

现在令$θ_{SVM}$为通过SVM学习获得的参数，令$θ_{BLR}$为通过贝叶斯逻辑回归学习得到的参数


